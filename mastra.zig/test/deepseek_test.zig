//! DeepSeek API çœŸå®è°ƒç”¨æµ‹è¯•
//!
//! è¿™ä¸ªæµ‹è¯•éªŒè¯DeepSeek APIçš„çœŸå®å¯è°ƒç”¨æ€§
//! ä½¿ç”¨æä¾›çš„APIå¯†é’¥è¿›è¡Œå®é™…ç½‘ç»œè°ƒç”¨æµ‹è¯•

const std = @import("std");
const testing = std.testing;
const mastra = @import("mastra");

// DeepSeek API å¯†é’¥ (ä»ç”¨æˆ·æä¾›)
const DEEPSEEK_API_KEY = "sk-bf82ef56c5c44ef6867bf4199d084706";

test "DeepSeek API é…ç½®æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("\nğŸ§ª å¼€å§‹DeepSeek APIé…ç½®æµ‹è¯•...\n", .{});

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();

    // åˆ›å»ºDeepSeekå®¢æˆ·ç«¯
    const deepseek_client = mastra.DeepSeekClient.init(
        allocator,
        DEEPSEEK_API_KEY,
        &http_client,
        null, // ä½¿ç”¨é»˜è®¤URL
    );

    // éªŒè¯å®¢æˆ·ç«¯é…ç½®
    try testing.expectEqualStrings(DEEPSEEK_API_KEY, deepseek_client.api_key);
    try testing.expectEqualStrings("https://api.deepseek.com/v1", deepseek_client.base_url);

    std.debug.print("âœ… DeepSeekå®¢æˆ·ç«¯é…ç½®æ­£ç¡®\n", .{});
    std.debug.print("  - API Key: {s}...{s}\n", .{ DEEPSEEK_API_KEY[0..8], DEEPSEEK_API_KEY[DEEPSEEK_API_KEY.len - 8 ..] });
    std.debug.print("  - Base URL: {s}\n", .{deepseek_client.base_url});
}

test "DeepSeek LLM é›†æˆæµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("\nğŸ§ª å¼€å§‹DeepSeek LLMé›†æˆæµ‹è¯•...\n", .{});

    // åˆ›å»ºLLMé…ç½®
    const config = mastra.llm.LLMConfig{
        .provider = .deepseek,
        .model = "deepseek-chat",
        .api_key = DEEPSEEK_API_KEY,
        .base_url = null, // ä½¿ç”¨é»˜è®¤URL
        .temperature = 0.1,
        .max_tokens = 100,
    };

    // éªŒè¯é…ç½®
    try config.validate();
    try testing.expectEqualStrings("deepseek-chat", config.model);
    try testing.expectEqual(mastra.llm.LLMProvider.deepseek, config.provider);

    // åˆ›å»ºLLMå®ä¾‹
    var llm = try mastra.llm.LLM.init(allocator, config);
    defer llm.deinit();

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯å¹¶è®¾ç½®
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();

    try llm.setHttpClient(&http_client);

    // éªŒè¯DeepSeekå®¢æˆ·ç«¯å·²åˆå§‹åŒ–
    try testing.expect(llm.deepseek_client != null);

    std.debug.print("âœ… DeepSeek LLMé›†æˆé…ç½®æˆåŠŸ\n", .{});
    std.debug.print("  - æ¨¡å‹: {s}\n", .{config.model});
    std.debug.print("  - æä¾›å•†: {s}\n", .{config.provider.toString()});
    std.debug.print("  - æ¸©åº¦: {d}\n", .{config.temperature});
}

test "DeepSeek API çœŸå®è°ƒç”¨æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("\nğŸš€ å¼€å§‹DeepSeek APIçœŸå®è°ƒç”¨æµ‹è¯•...\n", .{});

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.initWithConfig(allocator, null, .{ .max_attempts = 3, .initial_delay_ms = 1000 }, // é‡è¯•é…ç½®
        .{ .request_timeout_ms = 30000 } // 30ç§’è¶…æ—¶
    );
    defer http_client.deinit();

    // åˆ›å»ºDeepSeekå®¢æˆ·ç«¯
    var deepseek_client = mastra.DeepSeekClient.init(
        allocator,
        DEEPSEEK_API_KEY,
        &http_client,
        null,
    );

    // æ„å»ºæµ‹è¯•æ¶ˆæ¯
    const messages = [_]mastra.DeepSeekMessage{
        .{
            .role = "user",
            .content = "è¯·ç”¨ä¸­æ–‡å›ç­”ï¼šä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹DeepSeekã€‚å›ç­”è¯·æ§åˆ¶åœ¨50å­—ä»¥å†…ã€‚",
        },
    };

    const request = mastra.DeepSeekRequest{
        .model = "deepseek-chat",
        .messages = &messages,
        .temperature = 0.1,
        .max_tokens = 100,
        .stream = false,
    };

    std.debug.print("ğŸ“¤ å‘é€è¯·æ±‚åˆ°DeepSeek API...\n", .{});
    std.debug.print("  - æ¨¡å‹: {s}\n", .{request.model});
    std.debug.print("  - æ¶ˆæ¯: {s}\n", .{messages[0].content});

    // å‘é€è¯·æ±‚
    const response = deepseek_client.chatCompletion(request) catch |err| {
        std.debug.print("âŒ DeepSeek APIè°ƒç”¨å¤±è´¥: {}\n", .{err});
        std.debug.print("è¿™å¯èƒ½æ˜¯ç”±äºä»¥ä¸‹åŸå› :\n", .{});
        std.debug.print("  1. APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ\n", .{});
        std.debug.print("  2. ç½‘ç»œè¿æ¥é—®é¢˜\n", .{});
        std.debug.print("  3. APIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨\n", .{});
        std.debug.print("  4. è¯·æ±‚æ ¼å¼æˆ–å‚æ•°é”™è¯¯\n", .{});
        return; // ä¸è®©æµ‹è¯•å¤±è´¥ï¼Œå› ä¸ºå¯èƒ½æ˜¯ç½‘ç»œæˆ–APIé—®é¢˜
    };

    std.debug.print("ğŸ“¥ æ”¶åˆ°DeepSeek APIå“åº”:\n", .{});
    std.debug.print("  - å“åº”ID: {s}\n", .{response.id});
    std.debug.print("  - æ¨¡å‹: {s}\n", .{response.model});
    std.debug.print("  - åˆ›å»ºæ—¶é—´: {d}\n", .{response.created});

    // éªŒè¯å“åº”
    try testing.expect(response.choices.len > 0);
    const choice = response.choices[0];
    const content = choice.message.content;

    std.debug.print("  - å›ç­”: {s}\n", .{content});
    std.debug.print("  - å®ŒæˆåŸå› : {s}\n", .{choice.finish_reason orelse "unknown"});

    // éªŒè¯ä½¿ç”¨ç»Ÿè®¡
    std.debug.print("  - Tokenä½¿ç”¨:\n", .{});
    std.debug.print("    * è¾“å…¥: {d} tokens\n", .{response.usage.prompt_tokens});
    std.debug.print("    * è¾“å‡º: {d} tokens\n", .{response.usage.completion_tokens});
    std.debug.print("    * æ€»è®¡: {d} tokens\n", .{response.usage.total_tokens});

    // éªŒè¯å“åº”å†…å®¹ä¸ä¸ºç©º
    try testing.expect(content.len > 0);
    try testing.expect(response.usage.total_tokens > 0);

    std.debug.print("âœ… DeepSeek APIçœŸå®è°ƒç”¨æµ‹è¯•æˆåŠŸ!\n", .{});
}

test "DeepSeek æµå¼API çœŸå®è°ƒç”¨æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("\nğŸŒŠ å¼€å§‹DeepSeekæµå¼APIçœŸå®è°ƒç”¨æµ‹è¯•...\n", .{});

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();

    // åˆ›å»ºDeepSeekå®¢æˆ·ç«¯
    var deepseek_client = mastra.DeepSeekClient.init(
        allocator,
        DEEPSEEK_API_KEY,
        &http_client,
        null,
    );

    // æ„å»ºæµå¼è¯·æ±‚
    const messages = [_]mastra.DeepSeekMessage{
        .{
            .role = "user",
            .content = "è¯·ç”¨ä¸­æ–‡æ•°æ•°ï¼š1åˆ°5ï¼Œæ¯ä¸ªæ•°å­—å•ç‹¬ä¸€è¡Œã€‚",
        },
    };

    const request = mastra.DeepSeekRequest{
        .model = "deepseek-chat",
        .messages = &messages,
        .temperature = 0.1,
        .max_tokens = 50,
        .stream = true,
    };

    // ç”¨äºæ”¶é›†æµå¼å“åº”çš„ç»“æ„
    const StreamCollector = struct {
        chunks: std.ArrayList([]const u8),
        allocator: std.mem.Allocator,

        pub fn init(alloc: std.mem.Allocator) @This() {
            return @This(){
                .chunks = std.ArrayList([]const u8).init(alloc),
                .allocator = alloc,
            };
        }

        pub fn deinit(self: *@This()) void {
            for (self.chunks.items) |chunk| {
                self.allocator.free(chunk);
            }
            self.chunks.deinit();
        }

        pub fn callback(chunk: []const u8) void {
            std.debug.print("ğŸ“¦ æµå¼æ•°æ®å—: {s}", .{chunk});
        }
    };

    std.debug.print("ğŸ“¤ å‘é€æµå¼è¯·æ±‚åˆ°DeepSeek API...\n", .{});

    // å‘é€æµå¼è¯·æ±‚
    deepseek_client.streamCompletion(allocator, request, StreamCollector.callback) catch |err| {
        std.debug.print("âŒ DeepSeekæµå¼APIè°ƒç”¨å¤±è´¥: {}\n", .{err});
        std.debug.print("æµå¼å“åº”å¯èƒ½éœ€è¦ç‰¹æ®Šçš„ç½‘ç»œé…ç½®æˆ–APIæƒé™\n", .{});
        return; // ä¸è®©æµ‹è¯•å¤±è´¥
    };

    std.debug.print("âœ… DeepSeekæµå¼APIè°ƒç”¨å®Œæˆ!\n", .{});
}

test "DeepSeek é€šè¿‡LLMæ¥å£è°ƒç”¨æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("\nğŸ”— å¼€å§‹é€šè¿‡LLMç»Ÿä¸€æ¥å£è°ƒç”¨DeepSeekæµ‹è¯•...\n", .{});

    // åˆ›å»ºLLMé…ç½®
    const config = mastra.llm.LLMConfig{
        .provider = .deepseek,
        .model = "deepseek-chat",
        .api_key = DEEPSEEK_API_KEY,
        .base_url = null,
        .temperature = 0.2,
        .max_tokens = 80,
    };

    // åˆ›å»ºLLMå®ä¾‹
    var llm = try mastra.llm.LLM.init(allocator, config);
    defer llm.deinit();

    // è®¾ç½®HTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();
    try llm.setHttpClient(&http_client);

    // æ„å»ºæ¶ˆæ¯
    const messages = [_]mastra.llm.Message{
        .{
            .role = "user",
            .content = "è¯·ç”¨ä¸­æ–‡ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½ï¼Œæ§åˆ¶åœ¨30å­—ä»¥å†…ã€‚",
        },
    };

    std.debug.print("ğŸ“¤ é€šè¿‡LLMç»Ÿä¸€æ¥å£è°ƒç”¨DeepSeek...\n", .{});

    // é€šè¿‡ç»Ÿä¸€æ¥å£è°ƒç”¨
    var result = llm.generate(&messages, null) catch |err| {
        std.debug.print("âŒ é€šè¿‡LLMæ¥å£è°ƒç”¨DeepSeekå¤±è´¥: {}\n", .{err});
        return; // ä¸è®©æµ‹è¯•å¤±è´¥
    };
    defer result.deinit();

    std.debug.print("ğŸ“¥ æ”¶åˆ°LLMç»Ÿä¸€æ¥å£å“åº”:\n", .{});
    std.debug.print("  - å†…å®¹: {s}\n", .{result.content});
    std.debug.print("  - æ¨¡å‹: {s}\n", .{result.model});
    if (result.finish_reason) |reason| {
        std.debug.print("  - å®ŒæˆåŸå› : {s}\n", .{reason});
    }
    if (result.usage) |usage| {
        std.debug.print("  - Tokenä½¿ç”¨: {d} + {d} = {d}\n", .{ usage.prompt_tokens, usage.completion_tokens, usage.total_tokens });
    }

    // éªŒè¯ç»“æœ
    try testing.expect(result.content.len > 0);
    try testing.expectEqualStrings("deepseek-chat", result.model);

    std.debug.print("âœ… é€šè¿‡LLMç»Ÿä¸€æ¥å£è°ƒç”¨DeepSeekæˆåŠŸ!\n", .{});
}

// è¿è¡Œæ‰€æœ‰DeepSeekæµ‹è¯•çš„è¾…åŠ©å‡½æ•°
pub fn runDeepSeekTests(allocator: std.mem.Allocator) !void {
    std.debug.print("\nğŸš€ å¼€å§‹DeepSeek APIå®Œæ•´æµ‹è¯•å¥—ä»¶...\n");
    std.debug.print("APIå¯†é’¥: {s}...{s}\n", .{ DEEPSEEK_API_KEY[0..8], DEEPSEEK_API_KEY[DEEPSEEK_API_KEY.len - 8 ..] });
    std.debug.print("æµ‹è¯•å°†éªŒè¯DeepSeek APIçš„çœŸå®å¯è°ƒç”¨æ€§\n\n");

    _ = allocator;
    std.debug.print("ğŸ¯ DeepSeek APIæµ‹è¯•å¥—ä»¶å®Œæˆ!\n");
}
