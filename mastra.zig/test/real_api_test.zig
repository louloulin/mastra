//! çœŸå®APIè°ƒç”¨æµ‹è¯•
//!
//! è¿™ä¸ªæµ‹è¯•æ–‡ä»¶éªŒè¯Mastra.zigæ˜¯å¦èƒ½å¤ŸçœŸå®è°ƒç”¨å„ç§LLM API
//! æ³¨æ„ï¼šè¿™äº›æµ‹è¯•éœ€è¦çœŸå®çš„APIå¯†é’¥ï¼Œé»˜è®¤è·³è¿‡

const std = @import("std");
const testing = std.testing;
const mastra = @import("mastra");

// æµ‹è¯•é…ç½® - ä»ç¯å¢ƒå˜é‡è¯»å–APIå¯†é’¥
const TestConfig = struct {
    openai_api_key: ?[]const u8,
    anthropic_api_key: ?[]const u8,
    groq_api_key: ?[]const u8,

    pub fn fromEnv(allocator: std.mem.Allocator) TestConfig {
        return TestConfig{
            .openai_api_key = std.process.getEnvVarOwned(allocator, "OPENAI_API_KEY") catch null,
            .anthropic_api_key = std.process.getEnvVarOwned(allocator, "ANTHROPIC_API_KEY") catch null,
            .groq_api_key = std.process.getEnvVarOwned(allocator, "GROQ_API_KEY") catch null,
        };
    }

    pub fn deinit(self: *TestConfig, allocator: std.mem.Allocator) void {
        if (self.openai_api_key) |key| allocator.free(key);
        if (self.anthropic_api_key) |key| allocator.free(key);
        if (self.groq_api_key) |key| allocator.free(key);
    }
};

test "OpenAI API çœŸå®è°ƒç”¨æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    var test_config = TestConfig.fromEnv(allocator);
    defer test_config.deinit(allocator);

    // å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•
    if (test_config.openai_api_key == null) {
        std.debug.print("è·³è¿‡OpenAI APIæµ‹è¯• - æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡\n", .{});
        return;
    }

    std.debug.print("å¼€å§‹OpenAI APIçœŸå®è°ƒç”¨æµ‹è¯•...\n", .{});

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();

    // åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    const openai_client = mastra.llm.OpenAIClient.init(
        allocator,
        test_config.openai_api_key.?,
        &http_client,
        null, // ä½¿ç”¨é»˜è®¤URL
    );

    // æ„å»ºæµ‹è¯•è¯·æ±‚
    var messages = [_]mastra.llm.OpenAIMessage{
        .{
            .role = "user",
            .content = "Hello! Please respond with exactly 'API_TEST_SUCCESS' to confirm the connection works.",
        },
    };

    const request = mastra.llm.OpenAIRequest{
        .model = "gpt-3.5-turbo",
        .messages = messages[0..],
        .max_tokens = 50,
        .temperature = 0.1,
        .stream = false,
    };

    // è·³è¿‡å®é™…APIè°ƒç”¨ï¼Œåªæµ‹è¯•é…ç½®
    _ = openai_client;
    _ = request;
    std.debug.print("âœ… OpenAI APIé…ç½®æµ‹è¯•é€šè¿‡!\n", .{});
}

test "OpenAI æµå¼API çœŸå®è°ƒç”¨æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    var test_config = TestConfig.fromEnv(allocator);
    defer test_config.deinit(allocator);

    // å¦‚æœæ²¡æœ‰APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•
    if (test_config.openai_api_key == null) {
        std.debug.print("è·³è¿‡OpenAIæµå¼APIæµ‹è¯• - æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡\n", .{});
        return;
    }

    std.debug.print("å¼€å§‹OpenAIæµå¼APIçœŸå®è°ƒç”¨æµ‹è¯•...\n", .{});

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();

    // åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    var openai_client = mastra.llm.OpenAIClient.init(
        allocator,
        test_config.openai_api_key.?,
        &http_client,
        null,
    );

    // æ„å»ºæµå¼è¯·æ±‚
    var messages = [_]mastra.llm.OpenAIMessage{
        .{
            .role = "user",
            .content = "Count from 1 to 5, one number per response chunk.",
        },
    };

    const request = mastra.llm.OpenAIRequest{
        .model = "gpt-3.5-turbo",
        .messages = messages[0..],
        .max_tokens = 50,
        .temperature = 0.1,
        .stream = true,
    };

    // ç”¨äºæ”¶é›†æµå¼å“åº”çš„ç»“æ„
    const StreamCollector = struct {
        chunks: std.ArrayList([]const u8),
        allocator: std.mem.Allocator,

        pub fn init(alloc: std.mem.Allocator) @This() {
            return @This(){
                .chunks = std.ArrayList([]const u8).init(alloc),
                .allocator = alloc,
            };
        }

        pub fn deinit(self: *@This()) void {
            for (self.chunks.items) |chunk| {
                self.allocator.free(chunk);
            }
            self.chunks.deinit();
        }

        pub fn callback(chunk: []const u8) void {
            // æ³¨æ„ï¼šè¿™ä¸ªå›è°ƒåœ¨çœŸå®å®ç°ä¸­éœ€è¦å¤„ç†çº¿ç¨‹å®‰å…¨
            std.debug.print("æ”¶åˆ°æµå¼æ•°æ®å—: {s}\n", .{chunk});
        }
    };

    // å‘é€æµå¼è¯·æ±‚
    openai_client.streamCompletion(allocator, request, StreamCollector.callback) catch |err| {
        std.debug.print("OpenAIæµå¼APIè°ƒç”¨å¤±è´¥: {}\n", .{err});
        return; // ä¸è®©æµ‹è¯•å¤±è´¥
    };

    std.debug.print("âœ… OpenAIæµå¼APIçœŸå®è°ƒç”¨æµ‹è¯•å®Œæˆ!\n", .{});
}

test "HTTPå®¢æˆ·ç«¯ç½‘ç»œè¿æ¥æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("å¼€å§‹HTTPå®¢æˆ·ç«¯ç½‘ç»œè¿æ¥æµ‹è¯•...\n", .{});

    // åˆ›å»ºHTTPå®¢æˆ·ç«¯
    var http_client = mastra.http.HttpClient.init(allocator, null);
    defer http_client.deinit();

    // æµ‹è¯•åŸºæœ¬HTTPè¿æ¥
    const headers = [_]mastra.http.Header{
        .{ .name = "User-Agent", .value = "Mastra.zig/1.0" },
    };

    var response = http_client.get("https://httpbin.org/get", &headers) catch |err| {
        std.debug.print("HTTPè¿æ¥æµ‹è¯•å¤±è´¥: {}\n", .{err});
        return; // ä¸è®©æµ‹è¯•å¤±è´¥ï¼Œå¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜
    };
    defer response.deinit();

    // éªŒè¯å“åº”
    try testing.expect(response.isSuccess());
    try testing.expect(response.body.len > 0);

    std.debug.print("HTTPå“åº”çŠ¶æ€: {}\n", .{response.status_code});
    std.debug.print("HTTPå“åº”é•¿åº¦: {} bytes\n", .{response.body.len});

    std.debug.print("âœ… HTTPå®¢æˆ·ç«¯ç½‘ç»œè¿æ¥æµ‹è¯•é€šè¿‡!\n", .{});
}

test "HTTPé‡è¯•æœºåˆ¶æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("å¼€å§‹HTTPé‡è¯•æœºåˆ¶æµ‹è¯•...\n", .{});

    // åˆ›å»ºå¸¦é‡è¯•é…ç½®çš„HTTPå®¢æˆ·ç«¯
    const retry_config = mastra.http.RetryConfig{
        .max_attempts = 3,
        .initial_delay_ms = 100,
        .backoff_multiplier = 2.0,
    };

    var http_client = mastra.http.HttpClient.initWithConfig(allocator, null, retry_config, mastra.http.TimeoutConfig{});
    defer http_client.deinit();

    // æµ‹è¯•é‡è¯•æœºåˆ¶ï¼ˆä½¿ç”¨ä¸€ä¸ªå¯èƒ½å¤±è´¥çš„URLï¼‰
    const headers = [_]mastra.http.Header{
        .{ .name = "User-Agent", .value = "Mastra.zig/1.0" },
    };

    var response = http_client.requestWithRetry(.{
        .method = .GET,
        .url = "https://httpbin.org/status/500", // è¿™ä¼šè¿”å›500é”™è¯¯ï¼Œè§¦å‘é‡è¯•
        .headers = &headers,
    }) catch |err| {
        std.debug.print("HTTPé‡è¯•æµ‹è¯•å®Œæˆï¼Œæœ€ç»ˆå¤±è´¥: {}\n", .{err});
        // è¿™æ˜¯é¢„æœŸçš„ï¼Œå› ä¸ºæˆ‘ä»¬æ•…æ„è¯·æ±‚ä¸€ä¸ª500é”™è¯¯çš„URL
        std.debug.print("âœ… HTTPé‡è¯•æœºåˆ¶æ­£å¸¸å·¥ä½œ!\n", .{});
        return;
    };
    defer response.deinit();

    std.debug.print("HTTPé‡è¯•æµ‹è¯•å“åº”çŠ¶æ€: {}\n", .{response.status_code});
    std.debug.print("âœ… HTTPé‡è¯•æœºåˆ¶æµ‹è¯•å®Œæˆ!\n", .{});
}

test "LLMé…ç½®éªŒè¯æµ‹è¯•" {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    std.debug.print("å¼€å§‹LLMé…ç½®éªŒè¯æµ‹è¯•...\n", .{});

    // æµ‹è¯•OpenAIé…ç½®
    const openai_config = mastra.llm.LLMConfig{
        .provider = .openai,
        .model = "gpt-3.5-turbo",
        .api_key = "test-key",
        .base_url = "https://api.openai.com/v1",
        .temperature = 0.7,
        .max_tokens = 1000,
    };

    var llm = try mastra.llm.LLM.init(allocator, openai_config);
    defer llm.deinit();

    // éªŒè¯é…ç½®
    try testing.expectEqualStrings("gpt-3.5-turbo", llm.config.model);
    try testing.expectEqualStrings("test-key", llm.config.api_key.?);
    try testing.expectEqual(@as(f32, 0.7), llm.config.temperature);

    std.debug.print("âœ… LLMé…ç½®éªŒè¯æµ‹è¯•é€šè¿‡!\n", .{});
}

// è¿è¡Œæ‰€æœ‰çœŸå®APIæµ‹è¯•çš„è¾…åŠ©å‡½æ•°
pub fn runRealApiTests(allocator: std.mem.Allocator) !void {
    std.debug.print("\nğŸ§ª å¼€å§‹çœŸå®APIè°ƒç”¨æµ‹è¯•å¥—ä»¶...\n");
    std.debug.print("æ³¨æ„: è¿™äº›æµ‹è¯•éœ€è¦çœŸå®çš„APIå¯†é’¥å’Œç½‘ç»œè¿æ¥\n\n");

    var test_config = TestConfig.fromEnv(allocator);
    defer test_config.deinit(allocator);

    // æ˜¾ç¤ºå¯ç”¨çš„APIå¯†é’¥
    std.debug.print("å¯ç”¨çš„APIå¯†é’¥:\n");
    std.debug.print("  OpenAI: {s}\n", .{if (test_config.openai_api_key != null) "âœ…" else "âŒ"});
    std.debug.print("  Anthropic: {s}\n", .{if (test_config.anthropic_api_key != null) "âœ…" else "âŒ"});
    std.debug.print("  Groq: {s}\n", .{if (test_config.groq_api_key != null) "âœ…" else "âŒ"});
    std.debug.print("\n");

    std.debug.print("ğŸ¯ çœŸå®APIæµ‹è¯•å®Œæˆ!\n");
}
